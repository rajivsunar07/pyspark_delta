{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1993457-dc2a-461b-98c3-d1e1e9825247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Exploration of Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd7bf233-ed7e-46af-b685-20f6e6c1984e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark Session with Delta Lake support\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"DeltaLakeExploration\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d130d68e-39c1-409f-a2a5-d1d7c4b619c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define Delta Lake path\n",
    "delta_table_path = \"/tmp/delta_table\"\n",
    "\n",
    "# Create a simple DataFrame\n",
    "data = [(1, \"Alice\", 29), (2, \"Bob\", 34), (3, \"Charlie\", 23)]\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Write DataFrame to Delta format\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e86d1209-9b95-4846-8c1b-5c58612a30a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n| id|   name|age|\n+---+-------+---+\n|  3|Charlie| 23|\n|  1|  Alice| 29|\n|  2|    Bob| 34|\n+---+-------+---+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read Delta Table\n",
    "delta_df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "delta_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f1bb8af-8e8b-4b5a-9ae4-058f52427b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Append new data\n",
    "new_data = [(4, \"David\", 45), (5, \"Emma\", 31)]\n",
    "new_df = spark.createDataFrame(new_data, columns)\n",
    "new_df.write.format(\"delta\").mode(\"append\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5048daed-f1e5-4fd3-9f0b-9f9fcd247686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n| id|   name|age|\n+---+-------+---+\n|  3|Charlie| 23|\n|  1|  Alice| 29|\n|  4|  David| 45|\n|  5|   Emma| 31|\n|  2|    Bob| 34|\n+---+-------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Read updated table\n",
    "spark.read.format(\"delta\").load(delta_table_path).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ccf79cc-719e-44e4-b26d-30a9356b5b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Versions:\n+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|version|          timestamp|          userId|            userName|operation| operationParameters| job|          notebook|           clusterId|readVersion|   isolationLevel|isBlindAppend|    operationMetrics|userMetadata|          engineInfo|\n+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n|      4|2025-03-13 10:59:46|4022047655635652|uninterested.cent...|    WRITE|{mode -> Append, ...|null|{3494345668537905}|0313-094109-8px11srg|          3|WriteSerializable|         true|{numFiles -> 2, n...|        null|Databricks-Runtim...|\n|      3|2025-03-13 10:59:38|4022047655635652|uninterested.cent...|    WRITE|{mode -> Overwrit...|null|{3494345668537905}|0313-094109-8px11srg|          2|WriteSerializable|        false|{numFiles -> 3, n...|        null|Databricks-Runtim...|\n|      2|2025-03-13 10:50:46|4022047655635652|uninterested.cent...|    WRITE|{mode -> Append, ...|null|{3494345668537905}|0313-094109-8px11srg|          1|WriteSerializable|         true|{numFiles -> 2, n...|        null|Databricks-Runtim...|\n|      1|2025-03-13 10:50:02|4022047655635652|uninterested.cent...|    WRITE|{mode -> Append, ...|null|{3494345668537905}|0313-094109-8px11srg|          0|WriteSerializable|         true|{numFiles -> 2, n...|        null|Databricks-Runtim...|\n|      0|2025-03-13 10:49:40|4022047655635652|uninterested.cent...|    WRITE|{mode -> Overwrit...|null|{3494345668537905}|0313-094109-8px11srg|       null|WriteSerializable|        false|{numFiles -> 3, n...|        null|Databricks-Runtim...|\n+-------+-------------------+----------------+--------------------+---------+--------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------+------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Time Travel: View previous versions of data\n",
    "from delta.tables import *\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "print(\"Available Versions:\")\n",
    "spark.sql(f\"DESCRIBE HISTORY delta.`{delta_table_path}`\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5734875-f304-49f9-be78-283012cb22e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n| id|   name|age|\n+---+-------+---+\n|  3|Charlie| 23|\n|  1|  Alice| 29|\n|  2|    Bob| 34|\n+---+-------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Read an older version\n",
    "time_travel_df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n",
    "time_travel_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd833489-6662-408c-b4e9-11dad3d1a24f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Schema Evolution: Add a new column\n",
    "new_schema_data = [(6, \"Frank\", 39, \"M\")]\n",
    "new_columns = [\"id\", \"name\", \"age\", \"gender\"]\n",
    "new_schema_df = spark.createDataFrame(new_schema_data, new_columns)\n",
    "new_schema_df.write.format(\"delta\").mode(\"append\").option(\"mergeSchema\", \"true\").save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c54c6b01-7287-4c5d-aad0-b4e23c3b2e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------+\n| id|   name|age|gender|\n+---+-------+---+------+\n|  6|  Frank| 39|     M|\n|  3|Charlie| 23|  null|\n|  1|  Alice| 29|  null|\n|  4|  David| 45|  null|\n|  5|   Emma| 31|  null|\n|  2|    Bob| 34|  null|\n+---+-------+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the updated schema\n",
    "delta_df_updated = spark.read.format(\"delta\").load(delta_table_path)\n",
    "delta_df_updated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "698dedbc-69b2-4b04-bdd1-c951312e0bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[27]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Compaction: Optimize and Vacuum\n",
    "delta_table.optimize()\n",
    "delta_table.vacuum(retentionHours=168)  # Clean old versions after 7 days"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2297388459862926,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Delta Lake notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
